# -*- coding: utf-8 -*-
"""
å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã‚’å­¦ç¿’ã—è¿”ç­”ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆTransformerç‰ˆï¼‰

ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã—ãŸå°èª¬ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€
Transformerãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§æ–‡ç« ã®ç‰¹å¾´ã‚’å­¦ç¿’ã€‚
å­¦ç¿’å¾Œã€è³ªå•ã«å¯¾ã—ã¦å°èª¬ã®æ–‡ä½“ã§å¿œç­”ã‚’ç”Ÿæˆã€‚

ã€ä¸»ãªæ©Ÿèƒ½ã€‘
- è¤‡æ•°ã®å°èª¬ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•èª­ã¿è¾¼ã¿
- å­¦ç¿’ã—ãŸæ–‡ä½“ã§ã®æ–‡ç« ç”Ÿæˆ
"""

import os
import re
import math
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pickle
from tqdm import tqdm

# timeè¨ˆæ¸¬ç”¨ï¼ˆæœ€å°ï¼‰
import time


# ============================================================
# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå­¦ç¿’ã®è¨­å®šå€¤ï¼‰
# ============================================================
NOVEL_DIR = "./aozorabunko"     # å°èª¬ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã«aozorabunkoãƒ•ã‚©ãƒ«ãƒ€ã‚’ç½®ã
EMBEDDING_DIM = 512             # æ–‡å­—ã‚’æ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹éš›ã®æ¬¡å…ƒæ•°ï¼ˆTransformerã¯å¤§ãã‚æ¨å¥¨ï¼‰
NUM_HEADS = 8                   # Attentionãƒ˜ãƒƒãƒ‰ã®æ•°ï¼ˆEMBEDDING_DIMã®ç´„æ•°ã§ã‚ã‚‹å¿…è¦ã‚ã‚Šï¼‰
NUM_LAYERS = 6                  # Transformerã®å±¤ã®æ•°ï¼ˆæ·±ã„ã»ã©è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’å¯èƒ½ï¼‰
FF_DIM = 2048                   # Feed-Forwardå±¤ã®ä¸­é–“æ¬¡å…ƒï¼ˆé€šå¸¸ã¯EMBEDDING_DIMã®4å€ï¼‰
BATCH_SIZE = 192                # ä¸€åº¦ã«å­¦ç¿’ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã¾ã¨ã¾ã‚Šæ•°ï¼ˆTransformerã¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„ãŸã‚å°ã•ã‚ï¼‰
EPOCHS = 5                      # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½•å›ç¹°ã‚Šè¿”ã—å­¦ç¿’ã™ã‚‹ã‹
LEARNING_RATE = 0.0001          # å­¦ç¿’ã®é€Ÿåº¦ï¼ˆTransformerã¯å°ã•ã‚ã®å­¦ç¿’ç‡ãŒå®‰å®šï¼‰
MAX_LENGTH = 100                # ä¸€åº¦ã«å‡¦ç†ã™ã‚‹æ–‡å­—åˆ—ã®æœ€å¤§é•·
POS_ENCODING_MAX_LEN = 1000     # ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¯¾å¿œã§ãã‚‹æœ€å¤§é•·
MODEL_PATH = "novel_transformer_model.pth"        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å
VOCAB_PATH = "vocabulary_transformer.pkl"         # èªå½™ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å


class NovelDataset(Dataset):
    """
    å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Transformer ã®å­¦ç¿’ã«ä½¿ã†
    ã€Œå…¥åŠ›æ–‡å­—åˆ— â†’ æ¬¡ã®æ–‡å­—åˆ—ã€ã®ãƒšã‚¢ã«å¤‰æ›ã™ã‚‹ Dataset ã‚¯ãƒ©ã‚¹ã€‚

    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â–  è¶…ãƒ»å›³è§£ï¼šã©ã†ã‚„ã£ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ã®ï¼Ÿ
    ãƒ†ã‚­ã‚¹ãƒˆï¼š ABCDEFGHI ...

    max_length = 5 ã®ã¨ãï¼š

      i=0 â†’ å…¥åŠ›: ABCDE â†’ æ­£è§£: BCDEF
      i=1 â†’ å…¥åŠ›: BCDEF â†’ æ­£è§£: CDEFG
      i=2 â†’ å…¥åŠ›: CDEFG â†’ æ­£è§£: DEFGH
      ...

    ğŸ‘‰ Transformer ã«ã€Œé€£ç¶šã—ãŸæ–‡ç« ã®äºˆæ¸¬ã€ã‚’å­¦ã°ã›ã‚‹ãŸã‚ã®ä»•çµ„ã¿
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """

    def __init__(self, text, vocab, max_length=MAX_LENGTH):
        self.text = text              # ç”Ÿãƒ†ã‚­ã‚¹ãƒˆï¼ˆå·¨å¤§ã§ã‚‚1æœ¬ã ã‘ä¿æŒï¼‰
        self.vocab = vocab            # æ–‡å­—â†’ID ã®è¾æ›¸
        self.max_length = max_length  # 1ã‚µãƒ³ãƒ—ãƒ«ã‚ãŸã‚Šã®æ–‡å­—æ•°

        # ä½•å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ãŒä½œã‚Œã‚‹ã‹ã‚’è¨ˆç®—
        # ä¾‹ï¼‰len(text)=1000, max_length=200 â†’ 1000-200-1 = 799 ã‚µãƒ³ãƒ—ãƒ«
        self.dataset_length = max(0, len(self.text) - self.max_length - 1)


    def create_sequences(self, text):
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’ 1 æ–‡å­—ãšã¤ãšã‚‰ã—ãªãŒã‚‰
        ã€Œå…¥åŠ›100æ–‡å­— â†’ æ¬¡ã®100æ–‡å­—ã€ã‚’ä½œæˆã™ã‚‹ã€‚
        """

        sequences = []
        text_length = len(text)
        max_len = self.max_length

        # ä¾‹ï¼š100æ–‡å­—ãšã¤ã‚¹ãƒ©ã‚¤ãƒ‰ã—ã¦ãƒšã‚¢ã‚’ä½œæˆ
        for i in range(text_length - max_len - 1):
            # å…¥åŠ›æ–‡å­—åˆ—
            input_seq = text[i : i + max_len]
            # æ­£è§£ã®æ¬¡ã®æ–‡å­—åˆ—
            target_seq = text[i + 1 : i + max_len + 1]
            # ãƒšã‚¢ã¨ã—ã¦è¨˜éŒ²
            sequences.append((input_seq, target_seq))
        return sequences



    def __len__(self):
        """ã‚µãƒ³ãƒ—ãƒ«ã®ç·æ•°ã‚’è¿”ã™ï¼ˆDataLoader ãŒãƒãƒƒãƒå›æ•°ã‚’æ±ºã‚ã‚‹ã®ã«ä½¿ã†ï¼‰"""
        return self.dataset_length


    def __getitem__(self, idx):
        """
        idx ç•ªç›®ã® (å…¥åŠ›, æ­£è§£) ãƒšã‚¢ã‚’ä½œã£ã¦è¿”ã™ã€‚

        å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆï¼š
        - äº‹å‰ã«æ–‡å­—åˆ—ã‚’å…¨éƒ¨ä½œã£ã¦ä¿å­˜ã—ã¦ãŠãã®ã§ã¯ãªã
        - ã“ã“ã§åˆã‚ã¦ text ã‹ã‚‰ã‚¹ãƒ©ã‚¤ã‚¹ã—ã¦ä½œã‚‹
        """
        """
        æŒ‡å®š index ã® (å…¥åŠ›æ–‡å­—åˆ—, æ­£è§£æ–‡å­—åˆ—) ã‚’å–ã‚Šå‡ºã—ã€
        æ–‡å­— â†’ ID â†’ Tensor ã«å¤‰æ›ã—ã¦è¿”ã™ã€‚

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â–  è¶…ãƒ»å›³è§£ï¼šæ–‡å­—ã‚’ ID ã«å¤‰æ›ã™ã‚‹æµã‚Œ

        å…¥åŠ›æ–‡å­—åˆ—: ã€Œæ¢åµã¨ã¯ã€

        æ–‡å­— â†’ ID å¤‰æ›
          'æ¢' â†’ 125
          'åµ' â†’ 356
          'ã¨' â†’ 22
          'ã¯' â†’ 31

        â†’ ãƒ†ãƒ³ã‚½ãƒ«åŒ–
          tensor([125, 356, 22, 31])

        Transformer ã¯ã“ã® ID ã‚’ã€Œå˜èªã®ã‚ˆã†ã«ã€å‡¦ç†ã™ã‚‹ã€‚
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        """

        # 1. æ–‡å­—åˆ—ã‚¹ãƒ©ã‚¤ã‚¹ã®é–‹å§‹ä½ç½®ãƒ»çµ‚äº†ä½ç½®ã‚’æ±ºã‚ã‚‹
        start = idx
        end = idx + self.max_length

        # 2. ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œå…¥åŠ›ã€ã¨ã€Œæ¬¡ã®æ–‡å­—åˆ—ï¼ˆæ­£è§£ï¼‰ã€ã‚’åˆ‡ã‚Šå‡ºã™
        input_seq = self.text[start:end]        # é•·ã• max_length
        target_seq = self.text[start + 1:end + 1]  # 1æ–‡å­—å³ã‚·ãƒ•ãƒˆ

        # 3. æ–‡å­—åˆ— â†’ ID ãƒªã‚¹ãƒˆã«å¤‰æ›
        input_ids = []
        for char in input_seq:
            char_id = self.vocab.get(char, self.vocab["<UNK>"])#UNKã¨ã¯ã€AIãŒçŸ¥ã‚‰ãªã„æ–‡å­—ã®ã“ã¨ã€‚AI ãŒçŸ¥ã‚‰ãªã„æ–‡å­—ã§æ­¢ã¾ã‚‰ãšã€å­¦ç¿’ãƒ»æ¨è«–ã‚’ç¶šã‘ã‚‹ãŸã‚ã®ä¿é™º
            input_ids.append(char_id)

        target_ids = []
        for char in target_seq:
            char_id = self.vocab.get(char, self.vocab["<UNK>"])
            target_ids.append(char_id)

        # 4. PyTorch Tensor ã«å¤‰æ›ã—ã¦è¿”ã™
        return torch.tensor(input_ids), torch.tensor(target_ids)



class PositionalEncoding(nn.Module):
    """
    ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆPositional Encodingï¼‰

    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â–  ãªãœå¿…è¦ãªã®ï¼Ÿ
      Transformer ã¯ã€Œå…¨éƒ¨ã®æ–‡å­—ã‚’åŒæ™‚ã«ã€è¦‹ã‚‹ã®ã§ã€ãã®ã¾ã¾ã ã¨æ–‡å­—ã®é †ç•ªã‚’ç†è§£ã§ããªã„ã€‚

      ä¾‹ï¼š
          ã€Œç§ã¯å­¦ç”Ÿã§ã™ã€
          ã€Œå­¦ç”Ÿç§ã¯ã§ã™ã€
      â†’ ã©ã¡ã‚‰ã‚‚åŒã˜æ–‡å­—ã§ã‚‚ã€æ„å‘³ãŒé•ã†ï¼

      ãã“ã§ã€
      â˜… æ–‡å­—ãŒã€Œä½•ç•ªç›®ã«ã‚ã‚‹ã‹ã€ã‚’ç¤ºã™ä½ç½®æƒ…å ± ã‚’ sin/cos ã®æ³¢å½¢ã§ä½œã‚Šã€ãƒ™ã‚¯ãƒˆãƒ«ã«è¶³ã—è¾¼ã‚€ã€‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """

    def __init__(self, d_model, max_len=5000):
        """
        Args:
            d_model (int): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°
            max_len (int): å¯¾å¿œã§ãã‚‹æœ€å¤§ã®ç³»åˆ—é•·
        """
        super().__init__()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ä½ç½® 0,1,2,3,... ã®ç•ªå·ã‚’ä½œã‚‹
        # å½¢çŠ¶ï¼š[max_len, 1]
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        position = torch.arange(max_len).unsqueeze(1)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # sin/cos ã®æ³¢ã®å‘¨æœŸã‚’æ±ºã‚ã‚‹
        # æ¬¡å…ƒã”ã¨ã«ç•°ãªã‚‹å‘¨æœŸã«ã™ã‚‹ï¼ˆä½ç½®ã‚’åŒºåˆ¥ã™ã‚‹ãŸã‚ï¼‰
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)
        )

        # ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ä¿å­˜å…ˆ
        pe = torch.zeros(max_len, d_model)

        # å¶æ•°æ¬¡å…ƒï¼šsin æ³¢
        pe[:, 0::2] = torch.sin(position * div_term)

        # å¥‡æ•°æ¬¡å…ƒï¼šcos æ³¢
        pe[:, 1::2] = torch.cos(position * div_term)

        # ãƒ¢ãƒ‡ãƒ«ã«ä¿å­˜ã™ã‚‹ãŒã€å­¦ç¿’å¯¾è±¡ã§ã¯ãªã„ï¼ˆå›ºå®šå€¤ï¼‰
        self.register_buffer('pe', pe)


    def forward(self, x):
        """
        ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«åŠ ç®—ã™ã‚‹ã€‚

        Args:
            x: [batch_size, seq_len, d_model]

        Returns:
            x + pe : ä½ç½®æƒ…å ±ã‚’å«ã‚“ã ãƒ™ã‚¯ãƒˆãƒ«
        """

        # ç¾åœ¨ã®å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
        seq_len = x.size(1)

        # å¿…è¦ãªä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã ã‘å–ã‚Šå‡ºã™ â†’ [1, seq_len, d_model]
        pe = self.pe[:seq_len].unsqueeze(0)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # x + pe ã®å½¢çŠ¶
        #   x : [batch_size, seq_len, d_model]
        #   pe: [1,         seq_len, d_model]
        #
        #  â†’ PyTorch ã®ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã§ã€è‡ªå‹•çš„ã«
        #     å„ãƒãƒƒãƒã«åŒã˜ pe ã‚’è¶³ã—ã¦ãã‚Œã‚‹ã€‚
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        return x + pe


class NovelTransformer(nn.Module):
    """
    å°èª¬ã®æ–‡ä½“ã‚’å­¦ç¿’ã™ã‚‹Transformerãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    
    
    ã€æ§‹é€ ã€‘
    1. Embeddingå±¤: æ–‡å­—ID â†’ å¯†ãªãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã«å¤‰æ›
    2. Positional Encoding: ä½ç½®æƒ…å ±ã‚’ä»˜ä¸
    3. Transformer Encoderå±¤ï¼ˆè¤‡æ•°å±¤ï¼‰:
       - Multi-Head Self-Attention: æ–‡å­—é–“ã®é–¢é€£æ€§ã‚’å­¦ç¿’
       - Feed-Forward: ã•ã‚‰ã«ç‰¹å¾´ã‚’æŠ½å‡º
    4. å…¨çµåˆå±¤: æ¬¡ã«æ¥ã‚‹æ–‡å­—ã‚’äºˆæ¸¬
    
    ã€Multi-Head Attentionã¨ã¯ã€‘
    è¤‡æ•°ã®ã€Œè¦–ç‚¹ã€ï¼ˆãƒ˜ãƒƒãƒ‰ï¼‰ã§æ–‡ç« ã‚’åˆ†æã™ã‚‹ä»•çµ„ã¿ã€‚
    ä¾‹ãˆã°8ãƒ˜ãƒƒãƒ‰ãªã‚‰ï¼š
    - Head1: æ–‡æ³•çš„ãªé–¢ä¿‚ã‚’å­¦ç¿’
    - Head2: æ„å‘³çš„ãªé–¢ä¿‚ã‚’å­¦ç¿’
    - Head3: é•·è·é›¢ã®ä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’
    ...ãªã©ã€ãã‚Œãã‚ŒãŒç•°ãªã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã¾ã™ã€‚
    """
    
    def __init__(self, vocab_size, embedding_dim, num_heads, num_layers, ff_dim, max_len=MAX_LENGTH):
        """
        ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        
        Args:
            vocab_size (int): èªå½™ã®ã‚µã‚¤ã‚ºï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—ã®ç·æ•°ï¼‰
            embedding_dim (int): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°
            num_heads (int): Attentionãƒ˜ãƒƒãƒ‰ã®æ•°
            num_layers (int): Transformerã®å±¤ã®æ•°
            ff_dim (int): Feed-Forwardå±¤ã®ä¸­é–“æ¬¡å…ƒ
            max_len (int): å‡¦ç†ã§ãã‚‹æœ€å¤§æ–‡å­—åˆ—é•·
        """
        super(NovelTransformer, self).__init__()
        
        # Embeddingå±¤ï¼šæ–‡å­—IDï¼ˆæ•´æ•°ï¼‰ã‚’å¯†ãªãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå®Ÿæ•°ã®é…åˆ—ï¼‰ã«å¤‰æ›
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        
        # ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼šæ–‡å­—ã®é †åºæƒ…å ±ã‚’ä»˜ä¸
        self.pos_encoder = PositionalEncoding(embedding_dim, max_len=POS_ENCODING_MAX_LEN)
        
        # TransformerEncoderLayer: Self-Attention + Feed-Forward ã®ã‚»ãƒƒãƒˆ
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embedding_dim,      # d_model: å…¥å‡ºåŠ›ã®æ¬¡å…ƒæ•°ï¼ˆembedding_dimã¨åŒã˜ï¼‰
            nhead=num_heads,            # nhead: Attentionãƒ˜ãƒƒãƒ‰ã®æ•°ï¼ˆembedding_dimã¯nheadã§å‰²ã‚Šåˆ‡ã‚Œã‚‹å¿…è¦ã‚ã‚Šï¼‰
            dim_feedforward=ff_dim,     # dim_feedforward: Feed-Forwardå±¤ã®ä¸­é–“æ¬¡å…ƒï¼ˆé€šå¸¸ã¯d_modelã®4å€ï¼‰
            dropout=0.1,                # dropout: éå­¦ç¿’ã‚’é˜²ããŸã‚ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
            activation='gelu',          # æ´»æ€§åŒ–é–¢æ•°ï¼ˆGELUã¯Transformerã§ä¸€èˆ¬çš„ï¼‰
            batch_first=True            # ãƒãƒƒãƒã‚’æœ€åˆã®æ¬¡å…ƒã«ã™ã‚‹
        )
        
        # TransformerEncoder: ä¸Šè¨˜ã®layerã‚’num_layerså€‹ç©ã¿é‡ã­ã‚‹
        # å±¤ãŒæ·±ã„ã»ã©è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã§ãã‚‹
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        
        # å…¨çµåˆå±¤ï¼ˆç·šå½¢å¤‰æ›ï¼‰ï¼šTransformerã®å‡ºåŠ›ã‚’èªå½™ã‚µã‚¤ã‚ºã«å¤‰æ›
        # embedding_dimå€‹ã®å€¤ â†’ vocab_sizeå€‹ã®å€¤ï¼ˆå„æ–‡å­—ã®ç¢ºç‡ï¼‰
        self.fc = nn.Linear(embedding_dim, vocab_size)
        
        # Dropoutå±¤ï¼šéå­¦ç¿’é˜²æ­¢
        self.dropout = nn.Dropout(0.1)
        
        self.embedding_dim = embedding_dim
    
    def generate_square_subsequent_mask(self, sz):
        """
        å› æœçš„ãƒã‚¹ã‚¯ï¼ˆCausal Maskï¼‰ã®ç”Ÿæˆ
        
        ã€é‡è¦ã€‘æœªæ¥ã®æ–‡å­—ã‚’è¦‹ãªã„ã‚ˆã†ã«ã™ã‚‹ãƒã‚¹ã‚¯
        
        æ–‡ç« ç”Ÿæˆã§ã¯ã€Œç¾åœ¨ä½ç½®ã‚ˆã‚Šå¾Œã®æ–‡å­—ã€ã‚’è¦‹ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
        ä¾‹ï¼šã€Œæ¢åµã¨ã€ã‹ã‚‰ã€Œã¯ã€ã‚’äºˆæ¸¬ã™ã‚‹æ™‚ã€ã€Œã¯ä½•ã‹ã€ã‚’è¦‹ã¦ã¯ãƒ€ãƒ¡ã€‚
        
        ãƒã‚¹ã‚¯ã®ä¾‹ï¼ˆ4æ–‡å­—ã®å ´åˆï¼‰:
        [[0, -inf, -inf, -inf],   â† ä½ç½®0ã¯ä½ç½®0ã®ã¿å‚ç…§å¯èƒ½
         [0,    0, -inf, -inf],   â† ä½ç½®1ã¯ä½ç½®0,1ã‚’å‚ç…§å¯èƒ½
         [0,    0,    0, -inf],   â† ä½ç½®2ã¯ä½ç½®0,1,2ã‚’å‚ç…§å¯èƒ½
         [0,    0,    0,    0]]   â† ä½ç½®3ã¯å…¨ã¦å‚ç…§å¯èƒ½
        
        -infã®éƒ¨åˆ†ã¯Attentionè¨ˆç®—ã§ç„¡è¦–ã•ã‚Œã¾ã™ã€‚
        
        Args:
            sz (int): ç³»åˆ—é•·
        
        Returns:
            å½¢çŠ¶ [sz, sz] ã®ãƒã‚¹ã‚¯
        """
        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)
        return mask
    
    def forward(self, x):
        """
        é †ä¼æ’­ï¼šå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«ã«é€šã—ã¦å‡ºåŠ›ã‚’å¾—ã‚‹
        
        ã€å‡¦ç†ã®æµã‚Œã€‘
        å…¥åŠ›æ–‡å­—ID â†’ åŸ‹ã‚è¾¼ã¿ â†’ ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° â†’ Transformer â†’ å…¨çµåˆ â†’ å„æ–‡å­—ã®äºˆæ¸¬ã‚¹ã‚³ã‚¢
        
        Args:
            x (Tensor): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆå½¢çŠ¶: [ãƒãƒƒãƒã‚µã‚¤ã‚º, æ–‡å­—åˆ—é•·]ï¼‰
        
        Returns:
            Tensor: äºˆæ¸¬å‡ºåŠ›ï¼ˆå½¢çŠ¶: [ãƒãƒƒãƒã‚µã‚¤ã‚º, æ–‡å­—åˆ—é•·, èªå½™ã‚µã‚¤ã‚º]ï¼‰
        """
        # 1. æ–‡å­—IDã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
        # [batch_size, seq_len] â†’ [batch_size, seq_len, embedding_dim]
        embedded = self.embedding(x) * math.sqrt(self.embedding_dim)
        # âˆšembedding_dim ã‚’æ›ã‘ã‚‹ã®ã¯ã€Transformerè«–æ–‡ã§ã®æ¨™æº–çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        
        # 2. Dropoutã‚’é©ç”¨ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
        embedded = self.dropout(embedded)
        
        # 3. ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åŠ ç®—
        # å„æ–‡å­—ã«ã€Œä½•ç•ªç›®ã®æ–‡å­—ã‹ã€ã¨ã„ã†æƒ…å ±ã‚’ä»˜ä¸
        embedded = self.pos_encoder(embedded)
        
        # 4. å› æœçš„ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆï¼ˆæœªæ¥ã‚’è¦‹ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼‰
        seq_len = x.size(1)
        mask = self.generate_square_subsequent_mask(seq_len).to(x.device)
        
        # 5. Transformerã§æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸå‡¦ç†
        # Multi-Head Attentionã§å…¨æ–‡å­—é–“ã®é–¢é€£æ€§ã‚’å­¦ç¿’
        # Feed-Forwardã§ã•ã‚‰ã«ç‰¹å¾´ã‚’æŠ½å‡º
        # ã“ã‚Œã‚’è¤‡æ•°å±¤ç¹°ã‚Šè¿”ã™
        output = self.transformer(embedded, mask=mask)
        
        # 6. å…¨çµåˆå±¤ã§å„æ–‡å­—ã®äºˆæ¸¬ã‚¹ã‚³ã‚¢ã«å¤‰æ›
        # [batch_size, seq_len, embedding_dim] â†’ [batch_size, seq_len, vocab_size]
        output = self.fc(output)
        
        return output


def find_txt_files_recursively(root_dir):
    """å†å¸°çš„ã«å…¨ã¦ã®txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    txt_files = []
    
    def scan_directory(path):
        try:
            with os.scandir(path) as entries:
                for entry in entries:
                    try:
                        if entry.is_dir(follow_symlinks=False):
                            scan_directory(entry.path)
                        elif entry.is_file(follow_symlinks=False) and entry.name.endswith('.txt'):
                            txt_files.append(entry.path)
                    except (PermissionError, OSError):
                        continue
        except (PermissionError, OSError):
            pass
    
    scan_directory(root_dir)
    return txt_files


def load_novels(novel_dir=NOVEL_DIR, max_files=None, max_chars=10000000):
    """novelsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«èª­ã¿è¾¼ã‚€"""
    text = ""
    total_chars = 0
    files_loaded = 0
    
    print("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    txt_files = find_txt_files_recursively(novel_dir)
    
    if not txt_files:
        print(f"ã‚¨ãƒ©ãƒ¼: {novel_dir}ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(txt_files):,}å€‹")
    if max_files:
        print(f"èª­ã¿è¾¼ã¿ä¸Šé™: {max_files}ãƒ•ã‚¡ã‚¤ãƒ«")
    print(f"æœ€å¤§æ–‡å­—æ•°: {max_chars:,}æ–‡å­—")
    
    for txt_file in tqdm(txt_files, desc="ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­"):
        if max_files and files_loaded >= max_files:
            print(f"\nä¸Šé™ãƒ•ã‚¡ã‚¤ãƒ«æ•°({max_files})ã«é”ã—ãŸãŸã‚èª­ã¿è¾¼ã¿ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
            break
        
        if total_chars >= max_chars:
            print(f"\næœ€å¤§æ–‡å­—æ•°({max_chars:,}æ–‡å­—)ã«é”ã—ãŸãŸã‚èª­ã¿è¾¼ã¿ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
            break
        
        file_text = ""
        encodings = ['shift_jis', 'utf-8', 'cp932', 'euc-jp']
        
        for encoding in encodings:
            try:
                with open(txt_file, 'r', encoding=encoding) as f:
                    content = f.read()
                
                # ãƒ«ãƒ“è¨˜å·ã‚’é™¤å»
                content = re.sub(r'ã€Š[^ã€‹]*ã€‹', '', content)
                content = re.sub(r'ï¼»[^ï¼½]*ï¼½', '', content)
                content = re.sub(r'ï½œ', '', content)
                
                # é’ç©ºæ–‡åº«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ»ãƒ•ãƒƒã‚¿ãƒ¼ã‚’é™¤å»
                lines = content.split('\n')
                start_idx = 0
                end_idx = len(lines)
                
                for i, line in enumerate(lines):
                    if ('-------' in line or '------' in line or 
                        line.strip() == '' and i < 50):
                        continue
                    if (line.strip() != '' and not line.startswith('http') and
                        'é’ç©ºæ–‡åº«' not in line and i < 100):
                        start_idx = i
                        break
                
                for i in range(len(lines)-1, -1, -1):
                    if ('åº•æœ¬' in lines[i] or 'å…¥åŠ›' in lines[i] or
                        'æ ¡æ­£' in lines[i] or 'é’ç©ºæ–‡åº«' in lines[i]):
                        end_idx = i
                        break
                
                file_text = '\n'.join(lines[start_idx:end_idx]).strip()
                
                if len(file_text) > 100:
                    text += file_text + '\n'
                    total_chars += len(file_text)
                    files_loaded += 1
                    break
            
            except Exception:
                continue
    
    print(f"\nèª­ã¿è¾¼ã¿å®Œäº†: {files_loaded:,}ãƒ•ã‚¡ã‚¤ãƒ«, ç·æ–‡å­—æ•°: {total_chars:,}æ–‡å­—")
    return text


def create_vocabulary(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰èªå½™ï¼ˆä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å…¨æ–‡å­—ã®ãƒªã‚¹ãƒˆï¼‰ã‚’ä½œæˆ"""
    chars = sorted(list(set(text)))
    vocab = {'<PAD>': 0, '<UNK>': 1}
    for i, char in enumerate(chars):
        vocab[char] = i + 2
    idx2char = {v: k for k, v in vocab.items()}
    return vocab, idx2char


def train_model(model, dataloader, criterion, optimizer, scheduler, device, epochs=EPOCHS):
    """
    ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œ
    
    ã€å­¦ç¿’ã®ä»•çµ„ã¿ã€‘
    1. ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå…¥åŠ›æ–‡å­—åˆ—ã¨æ­£è§£ã®æ¬¡ã®æ–‡å­—åˆ—ï¼‰
    2. ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’è¡Œã†ï¼ˆTransformerã¯å…¨æ–‡å­—ã‚’ä¸¦åˆ—å‡¦ç†ï¼‰
    3. äºˆæ¸¬ã¨æ­£è§£ã®å·®ï¼ˆæå¤±ï¼‰ã‚’è¨ˆç®—
    4. èª¤å·®é€†ä¼æ’­ã§å‹¾é…ã‚’è¨ˆç®—
    5. é‡ã¿ã‚’æ›´æ–°ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ï¼‰
    6. ä¸Šè¨˜ã‚’å…¨ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ç¹°ã‚Šè¿”ã™ï¼ˆ1ã‚¨ãƒãƒƒã‚¯ï¼‰
    7. ã‚¨ãƒãƒƒã‚¯æ•°ã ã‘ç¹°ã‚Šè¿”ã™
    
    ã€LSTMã¨ã®é•ã„ã€‘
    - LSTMã¯é †æ¬¡å‡¦ç†ã ãŒã€Transformerã¯ä¸¦åˆ—å‡¦ç†
    - ãã®ãŸã‚ã€GPUã‚’ä½¿ã£ãŸå ´åˆã®å­¦ç¿’é€Ÿåº¦ãŒå¤§å¹…ã«å‘ä¸Š
    
    Args:
        model (nn.Module): å­¦ç¿’å¯¾è±¡ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«
        dataloader (DataLoader): å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¾›çµ¦ã™ã‚‹ãƒ­ãƒ¼ãƒ€ãƒ¼
        criterion: æå¤±é–¢æ•°ï¼ˆäºˆæ¸¬ã¨æ­£è§£ã®å·®ã‚’è¨ˆç®—ï¼‰
        optimizer: æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆé‡ã¿ã®æ›´æ–°æ–¹æ³•ï¼‰
        scheduler: å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ï¼ˆå­¦ç¿’ç‡ã‚’å‹•çš„ã«èª¿æ•´ï¼‰
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ï¼ˆCPU or GPUï¼‰
        epochs (int): å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã™å›æ•°
    """
    
    model.train()
    print(f"\nå­¦ç¿’é–‹å§‹ï¼ˆã‚¨ãƒãƒƒã‚¯æ•°: {epochs}ï¼‰")
    
#    best_loss = float('inf')
#    patience = 3
#    patience_counter = 0
    
    # å„ã‚¨ãƒãƒƒã‚¯ã®å‡¦ç†
    for epoch in range(epochs):
        total_loss = 0  # ã“ã®ã‚¨ãƒãƒƒã‚¯ã§ã®ç´¯ç©æå¤±
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤ºã—ãªãŒã‚‰ãƒãƒƒãƒå‡¦ç†
        progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        
        for inputs, targets in progress_bar:
            # ãƒ‡ãƒ¼ã‚¿ã‚’GPU/CPUã«è»¢é€
            inputs, targets = inputs.to(device), targets.to(device)
            # å‹¾é…ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆå‰ã®ãƒãƒƒãƒã®å½±éŸ¿ã‚’æ¶ˆã™ï¼‰
            optimizer.zero_grad()

            
            # é †ä¼æ’­ï¼šäºˆæ¸¬ã‚’è¡Œã†
            # Transformerã¯å…¨æ–‡å­—ã‚’åŒæ™‚ã«å‡¦ç†ï¼ˆä¸¦åˆ—åŒ–ï¼‰
            outputs = model(inputs)
            
            # æå¤±ã‚’è¨ˆç®—
            # view()ã§å½¢çŠ¶ã‚’å¤‰æ›ï¼š(ãƒãƒƒãƒ, æ–‡å­—åˆ—é•·, èªå½™ã‚µã‚¤ã‚º) â†’ (ãƒãƒƒãƒÃ—æ–‡å­—åˆ—é•·, èªå½™ã‚µã‚¤ã‚º)
            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))
            
            # é€†ä¼æ’­ï¼šå‹¾é…ã‚’è¨ˆç®—
            loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼šå‹¾é…ãŒå¤§ãããªã‚Šã™ãã‚‹ã®ã‚’é˜²ã
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            
            # é‡ã¿ã‚’æ›´æ–°
            optimizer.step()
            
            total_loss += loss.item()
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch+1}/{epochs}, å¹³å‡Loss: {avg_loss:.4f}")
        
        scheduler.step(avg_loss)
        
        # # Early Stoppingåˆ¤å®š
        # if avg_loss < best_loss - 0.01:  # 0.01ä»¥ä¸Šæ”¹å–„ã—ãŸå ´åˆ
        #     best_loss = avg_loss
        #     patience_counter = 0
        #     #ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä¿å­˜
        #     torch.save(model.state_dict(), BEST_MODEL_PATH)
            
        #     print(f"  â†’ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«æ›´æ–°ï¼ˆLoss: {best_loss:.4f}ï¼‰")
        # else:
        #     patience_counter += 1
        #     print(f"  â†’ æ”¹å–„ãªã—ï¼ˆ{patience_counter}/{patience}ï¼‰")
        
        # if patience_counter >= patience:
        #     print(f"\næ—©æœŸçµ‚äº†: {patience}ã‚¨ãƒãƒƒã‚¯é€£ç¶šã§æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        #     model.load_state_dict(torch.load(BEST_MODEL_PATH, weights_only=True))
            
        #     break





def generate_response(model, prompt, vocab, idx2char, device, max_length=200, temperature=0.8):

    """
    è³ªå•ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆ
    
    ã€æ–‡ç« ç”Ÿæˆã®ä»•çµ„ã¿ã€‘
    1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè³ªå•æ–‡ï¼‰ã‚’å…¥åŠ›
    2. TransformerãŒæ¬¡ã®æ–‡å­—ã‚’äºˆæ¸¬ï¼ˆå…¨æ–‡å­—ã‚’åŒæ™‚ã«è¦‹ã¦åˆ¤æ–­ï¼‰
    3. äºˆæ¸¬ã•ã‚ŒãŸæ–‡å­—ã‚’å…¥åŠ›ã«è¿½åŠ 
    4. å†åº¦æ¬¡ã®æ–‡å­—ã‚’äºˆæ¸¬
    5. 2-4ã‚’ç¹°ã‚Šè¿”ã—ã¦æ–‡ç« ã‚’ç”Ÿæˆ
    
    ã€temperatureï¼ˆæ¸©åº¦ï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘
    - ä½ã„ï¼ˆ0.5ãªã©ï¼‰: ç¢ºå®Ÿãªäºˆæ¸¬ã‚’é¸ã¶ â†’ å®‰å®šã—ãŸæ–‡ç« ã ãŒå˜èª¿
    - é«˜ã„ï¼ˆ1.0ä»¥ä¸Šï¼‰: ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒé«˜ã„ â†’ å¤šæ§˜ã ãŒä¸è‡ªç„¶ãªå ´åˆã‚‚
    
    Args:
        model (nn.Module): å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        prompt (str): è³ªå•æ–‡ï¼ˆæ–‡ç« ç”Ÿæˆã®èµ·ç‚¹ï¼‰
        vocab (dict): æ–‡å­—â†’IDå¤‰æ›è¾æ›¸
        idx2char (dict): IDâ†’æ–‡å­—å¤‰æ›è¾æ›¸
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        max_length (int): ç”Ÿæˆã™ã‚‹æœ€å¤§æ–‡å­—æ•°
        temperature (float): ç”Ÿæˆã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ï¼ˆ0.1ã€œ2.0ç¨‹åº¦ï¼‰
    
    Returns:
        str: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸæ–‡ç« 
    """

    
    # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šï¼ˆDropoutãªã©ã‚’ç„¡åŠ¹åŒ–ï¼‰
    model.eval()
    

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ•°å€¤IDã®ãƒªã‚¹ãƒˆã«å¤‰æ›
    input_ids = [vocab.get(c, vocab['<UNK>']) for c in prompt]

    # æœ€åˆã‹ã‚‰é•·ã™ãã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å ´åˆã¯ã€æœ«å°¾ MAX_LENGTH ã ã‘æ®‹ã™
    if len(input_ids) > MAX_LENGTH:
        input_ids = input_ids[-MAX_LENGTH:]


    # ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆï¼‰
    generated = prompt

    # å‹¾é…è¨ˆç®—ã‚’ç„¡åŠ¹åŒ–ï¼ˆæ¨è«–æ™‚ã¯ä¸è¦ãªã®ã§é«˜é€ŸåŒ–ï¼‰
    with torch.no_grad():
        # æŒ‡å®šã•ã‚ŒãŸé•·ã•ã¾ã§æ–‡å­—ã‚’ç”Ÿæˆ
        for _ in range(max_length):
            # ç¾åœ¨ã®å…¥åŠ›ã‹ã‚‰æ¬¡ã®æ–‡å­—ã‚’äºˆæ¸¬ã€‚Transformerã¯æ¯å›å…¨ç³»åˆ—ã‚’å…¥åŠ›ã™ã‚‹
            #input_tensor = torch.tensor([input_ids]).to(device)
            
            input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)
            
            output = model(input_tensor)

            # æœ€å¾Œã®æ™‚åˆ»ã®å‡ºåŠ›ã‹ã‚‰æ¬¡ã®æ–‡å­—ã®ç¢ºç‡åˆ†å¸ƒã‚’å–å¾—
            logits = output[0, -1, :] / temperature  # temperatureã§ç¢ºç‡åˆ†å¸ƒã‚’èª¿æ•´
            probs = torch.softmax(logits, dim=0)     # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§ç¢ºç‡ã«å¤‰æ›

            
            # ç¢ºç‡åˆ†å¸ƒã«å¾“ã£ã¦æ¬¡ã®æ–‡å­—ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ï¼ˆç¢ºç‡ãŒé«˜ã„æ–‡å­—ã»ã©é¸ã°ã‚Œã‚„ã™ã„ãŒã€ä½ç¢ºç‡ã®æ–‡å­—ã‚‚é¸ã°ã‚Œã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
            next_char_idx = torch.multinomial(probs, 1).item()
            next_char = idx2char.get(next_char_idx, '')

            # çµ‚äº†æ¡ä»¶ï¼šå¥ç‚¹ãªã©ã§æ–‡ãŒçµ‚ã‚ã‚Šã€ã‹ã¤ååˆ†ãªé•·ã•ãŒã‚ã‚‹å ´åˆ
            if next_char in ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n'] and len(generated) > len(prompt) + 10:
                generated += next_char
                break

            # ç”Ÿæˆã•ã‚ŒãŸæ–‡å­—ã‚’è¿½åŠ 
            generated += next_char
            input_ids.append(next_char_idx)

            # MAX_LENGTHã‚’è¶…ãˆãªã„ã‚ˆã†ã«å¤ã„éƒ¨åˆ†ã‚’å‰Šé™¤
            if len(input_ids) > MAX_LENGTH:
                input_ids = input_ids[-MAX_LENGTH:]

    return generated



# è¨ˆæ¸¬é–¢æ•°
def _t(msg, t0, device=None):
    if device is not None and device.type == "cuda":
        torch.cuda.synchronize()
    print(f"[TIME] {msg}: {time.perf_counter() - t0:.2f}s") 


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    
    ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®æµã‚Œã€‘
    1. GPUãŒä½¿ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
    2. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
       - ã‚ã‚‹å ´åˆï¼šãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
       - ãªã„å ´åˆï¼šå°èª¬ã‚’èª­ã¿è¾¼ã¿ã€å­¦ç¿’ã‚’å®Ÿè¡Œã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    3. è³ªå•ã«å¯¾ã—ã¦å¿œç­”ã‚’ç”Ÿæˆãƒ»è¡¨ç¤º
    """
    
    # ============================================================
    # 1. ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®šï¼ˆGPU or CPUï¼‰
    # ============================================================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
    
    # ============================================================
    # 2. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèªã¨èª­ã¿è¾¼ã¿ or æ–°è¦å­¦ç¿’
    # ============================================================
    #ä¿å­˜æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆ
    if os.path.exists(MODEL_PATH) and os.path.exists(VOCAB_PATH):
        print("\nå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
        with open(VOCAB_PATH, 'rb') as f:
            vocab, idx2char = pickle.load(f)
        
        model = NovelTransformer(
            vocab_size=len(vocab),
            embedding_dim=EMBEDDING_DIM,
            num_heads=NUM_HEADS,
            num_layers=NUM_LAYERS,
            ff_dim=FF_DIM
        ).to(device)
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))
        print("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    #ä¿å­˜æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã€€â‡’å­¦ç¿’
    else:
        print("\nå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
        
        #æ™‚é–“è¨ˆæ¸¬
        t0 = time.perf_counter()
        
        # å°èª¬ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        # max_files: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®ä¸Šé™   max_chars: èª­ã¿è¾¼ã‚€æ–‡å­—æ•°ã®ä¸Šé™
        text = load_novels(max_files=3000, max_chars=10_000_000)

        #æ™‚é–“è¨ˆæ¸¬
        _t("load_novels", t0)

        if text is None or len(text) < 1000:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
        
        
        print(f"ç·æ–‡å­—æ•°: {len(text):,}æ–‡å­—")

        #æ™‚é–“è¨ˆæ¸¬        
        t0 = time.perf_counter()
        # èªå½™ã®ä½œæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆä¸­ã®å…¨ãƒ¦ãƒ‹ãƒ¼ã‚¯æ–‡å­—ã‚’æŠ½å‡ºï¼‰
        vocab, idx2char = create_vocabulary(text)
        print(f"èªå½™ã‚µã‚¤ã‚º: {len(vocab)}")
        
        
        #æ™‚é–“è¨ˆæ¸¬
        _t("create_vocabulary", t0)
       
        
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
        dataset = NovelDataset(text, vocab)
        
        dataloader = DataLoader(
            dataset,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=4,        # CPU ã®ã‚³ã‚¢æ•°ã«åˆã‚ã›ã¦èª¿æ•´
            pin_memory=True,      # GPU ã¸ã®è»¢é€ã‚’é«˜é€ŸåŒ–
            persistent_workers=True   # ä½•åº¦ã‚‚ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç«‹ã¦ç›´ã•ãªã„
        )        
        
       
        
        print(f"å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(dataset):,}")
        
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        model = NovelTransformer(
            vocab_size=len(vocab),
            embedding_dim=EMBEDDING_DIM,
            num_heads=NUM_HEADS,
            num_layers=NUM_LAYERS,
            ff_dim=FF_DIM
        ).to(device)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¡¨ç¤º
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}å€‹")
        
        # æå¤±é–¢æ•°ï¼šäºˆæ¸¬ã¨æ­£è§£ã®å·®ã‚’è¨ˆç®—ï¼ˆã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ï¼‰
        criterion = nn.CrossEntropyLoss()
        
        # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼šAdamWï¼ˆTransformerã§æ¨å¥¨ã•ã‚Œã‚‹Adamæ”¹è‰¯ç‰ˆï¼‰
        optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)
        
        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’è¿½åŠ 
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.5, patience=2
        )
        

        t0 = time.perf_counter()  # â˜…è¿½åŠ 
        _t("train_model (start sync)", t0, device=device)  # â˜…è¿½åŠ ï¼ˆé–‹å§‹å‰ã«åŒæœŸï¼‰
        
        # å­¦ç¿’ã®å®Ÿè¡Œ
        train_model(model, dataloader, criterion, optimizer, scheduler, device)


        _t("train_model (total)", t0, device=device)  # â˜…è¿½åŠ ï¼ˆçµ‚äº†å¾Œã‚‚åŒæœŸã—ã¦æ­£ã—ãæ¸¬ã‚‹ï¼‰



        
        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        torch.save(model.state_dict(), MODEL_PATH)
        with open(VOCAB_PATH, 'wb') as f:
            pickle.dump((vocab, idx2char), f)
        print(f"\nãƒ¢ãƒ‡ãƒ«ã‚’ {MODEL_PATH} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # ============================================================
    # 3. ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã—ã¦è³ªå•ã«å¿œç­”
    # ============================================================
    print("\n" + "="*60)
    print("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆèµ·å‹•ï¼ˆTransformerç‰ˆï¼‰")
    print("="*60)
    
    # è³ªå•ãƒªã‚¹ãƒˆï¼ˆãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ï¼–ç‚¹ã€‚
    questions = [
        "æ¢åµã¨ã¯",
        "çŠ¯äººã®å¿ƒç†ã¯",
        "ã“ã®äº‹ä»¶ã®çœŸç›¸ã¯",
        "ä¸å¯è§£ãªå‡ºæ¥äº‹",
        "å¥‡å¦™ãªæ¤…å­",
        "ã‚´ãƒªãƒ©ã¯é£Ÿã¹ã¾ã—ãŸã‹ï¼Ÿ"
    ]
    
    # å„è³ªå•ã«å¯¾ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
    for question in questions:
        print(f"\nè³ªå•: {question}")
        print("-" * 60)
        response = generate_response(model, question, vocab, idx2char, device, 
                                    max_length=300, temperature=0.7)
        print(f"å›ç­”: {response}")
        print("-" * 60)


# ============================================================
# ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ============================================================
if __name__ == "__main__":
    if not os.path.exists(NOVEL_DIR):
        print(f"ã‚¨ãƒ©ãƒ¼: {NOVEL_DIR} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    else:
        main()


##############################
# ============================================================
# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆèµ·å‹•ï¼ˆTransformerç‰ˆï¼‰
# ============================================================

# è³ªå•: æ¢åµã¨ã¯
# ------------------------------------------------------------
# å›ç­”: æ¢åµã¨ã¯ã€æ—¥æœ¬äººã¨ã¯çš†ã€ç³å–°ã„ã¨ãªã£ã¦ã„ã‚‹ã€‚
# ------------------------------------------------------------

# è³ªå•: çŠ¯äººã®å¿ƒç†ã¯
# ------------------------------------------------------------
# å›ç­”: çŠ¯äººã®å¿ƒç†ã¯ã€æ¬§æ´²å¤§æˆ¦ä»¥å¾Œã®é—˜äº‰ã«åå¯¾ã—ã¦ã„ã‚‹ã€‚
# ------------------------------------------------------------

# è³ªå•: ã“ã®äº‹ä»¶ã®çœŸç›¸ã¯
# ------------------------------------------------------------
# å›ç­”: ã“ã®äº‹ä»¶ã®çœŸç›¸ã¯ã™ã¹ã¦æ·±ãå‚·ã¤ããã†ãªã‚‚ã®ã ã£ãŸã€‚
# ------------------------------------------------------------

# è³ªå•: ä¸å¯è§£ãªå‡ºæ¥äº‹
# ------------------------------------------------------------
# å›ç­”: ä¸å¯è§£ãªå‡ºæ¥äº‹ã«å°±ã„ã¦ã€å¤¢æƒ³ã—ã¦ã„ãŸäº‹ã§ã‚ã£ãŸã€‚
# ------------------------------------------------------------

# è³ªå•: å¥‡å¦™ãªæ¤…å­
# ------------------------------------------------------------
# å›ç­”: å¥‡å¦™ãªæ¤…å­ã«è…°ã‹ã‘ã¦ã€ã„ã¾ã¾ã§ã¯ã€ç§ã«ã‚‚ã€ã“ã®å°‘å¹´å°‘å¥³ãŒã€ãã®ã‚ˆã†ãªè¡æ˜ãªè¡¨æƒ…ã‚’ã—ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã‚ã‚Œã‚‹ã€‚
# ------------------------------------------------------------

# è³ªå•: ã‚´ãƒªãƒ©ã¯é£Ÿã¹ã¾ã—ãŸã‹ï¼Ÿ
# ------------------------------------------------------------
# å›ç­”: ã‚´ãƒªãƒ©ã¯é£Ÿã¹ã¾ã—ãŸã‹ï¼Ÿ
# ã€€ã“ã®ä¸–ã®ä¸­ã§ã¯ã€ã‚ãŸã—ãŸã¡ã¯ã€æ°—ãŒã¤ã„ã¦ã„ã¾ã—ãŸã€‚
# ------------------------------------------------------------
